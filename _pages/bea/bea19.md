---
title: 19th Workshop on Innovative Use of NLP for Building Educational Applications
permalink: /bea/2024
redirect_from: /bea/19
sidebar:
  nav: "bea"
toc: true
toc_sticky: true
toc_icon: 'cog'
gold:
  - url: https://www.cambridge.org/
    image_path: "/assets/images/logos/sponsors/bea2023/cambridge-upa.png"
    alt: "Cambridge University Press & Assessment Logo"
    title: "Cambridge University Press & Assessment"
  - url: https://www.fernuni-hagen.de/english/research/clusters/catalpa/
    image_path: "/assets/images/logos/sponsors/bea2023/CATALPA.JPG"
    alt: "CATALPA Logo"
    title: "CATALPA"
  - url: https://englishtest.duolingo.com/
    image_path: "/assets/images/logos/sponsors/bea2024/DET-v8-1536x2008.png"
    alt: "Duolingo English Test Logo"
    title: "Duolingo English Test"
  - url: https://www.ets.org
    image_path: "/assets/images/logos/sponsors/bea2023/ets.jpg"
    alt: "ETS Logo"
    title: "ETS"
  - url: https://nbme.org
    image_path: "/assets/images/logos/sponsors/bea2023/nbme.png"
    alt: "NBME Logo"
    title: "NBME"
---

![toronto](/assets/images/venues/mexico-city-hilton-reforma.jpeg)

<table>
<thead>
<tr>
<th colspan="2"><span style="font-size: larger;">Quick Info</span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="width: 30%;"><strong>Co-located with</strong></td>
<td><a target="_blank" href="https://2024.naacl.org/">NAACL 2024</a></td>
</tr>
<tr>
<td><strong>Location</strong></td>
<td>Mexico City, Mexico</td>
</tr>
<tr>
<td><strong>Deadline</strong></td>
<td><strike>March 10</strike> March 16, 2024</td>
</tr>
<tr>
<td><strong>Date</strong></td>
<td>June 20, 2024</td>
</tr>
<tr>
<td><strong>Organizers</strong></td>
<td>Ekaterina Kochmar, Jill Burstein, Andrea Horbach, Ronja Laarmann-Quante, Ana√Øs Tack, Victoria Yaneva, Zheng Yuan, and Marie Bexte</td>
</tr>
<tr>
<td><strong>Contact</strong></td>
<td><a href="mailto:bea.nlp.workshop@gmail.com">bea.nlp.workshop@gmail.com</a></td>
</tr>
</tbody>
</table>

## Workshop Description

The **BEA Workshop** is a leading venue for NLP innovation in the context of educational applications.
It is one of the largest one-day workshops in the ACL community with over 100 registered attendees in the past several years.
The growing interest in educational applications and a diverse community of researchers involved resulted in the creation of the [Special Interest Group in Educational Applications (SIGEDU)](https://www.aclweb.org/adminwiki/index.php?title=2019Q3_Reports:_SIGEDU) in 2017, which currently has over 300 members.

The **workshop's continuing growth** reflects how technology is increasingly fulfilling societal demands.
For instance, the BEA16 workshop in 2021 hosted a panel discussion on "New Challenges for Educational Technology in the Time of the Pandemic" addressing the pressing issues around COVID-19.
Additionally, NLP has evolved to aid diverse learning domains, including writing, speaking, reading, science, and mathematics, as well as the related intra-personal (e.g., self-confidence) and inter-personal (e.g., peer collaboration) skills.
Within these areas, the community continues to develop and deploy innovative NLP approaches for use in educational settings.

Another significant advancement in educational applications within the Computational Linguistics (CL) community is the **continuing series of shared-task competitions** organized by and hosted at the BEA workshop.
Over the years, this initiative has included four dedicated tasks focused solely on grammatical error detection and correction.
Moreover, NLP/Education shared tasks have expanded into novel research areas, such as the [Automated Evaluation of Scientific Writing](/sharedtask/2016) at BEA11, [Native Language Identification](/sharedtask/2017) at BEA12, [Second Language Acquisition Modeling](/sharedtask/2018-SLAM) at BEA13, [Complex Word Identification](/sharedtask/2018-CWI) at BEA13, and [Generating AI Teacher Responses in Educational Dialogues](/sharedtask/2023) at BEA18.
These competitions have significantly bolstered the visibility and interest in our field.

The **19th BEA workshop** will adopt the same format as the 2023 edition and will be **hybrid**, integrating both in-person and virtual presentations and attendance.
The workshop will feature a **keynote talk**, a main workshop track with **oral presentation sessions** and **large poster sessions** to facilitate the presentation of a wide array of original research.
Moreover, there will be **two shared task tracks**, with each comprising an oral *overview presentation* by the shared task organizers and several *poster presentations* by the shared task participants.

We expect that the workshop will continue to highlight novel technologies and opportunities, including the use of state-of-the-art large language models in educational applications, and challenges around responsible AI for educational NLP, in English as well as other languages.

## Sponsors

Gold Sponsors
: {% include gallery id="gold" layout="half" %}

Sponsoring Opportunities
: We are extremely grateful to our sponsors for the past workshops: in the recent years, we have been supported by [Cambridge University Press & Assessment](https://www.cambridge.org/), [CATALPA](https://www.fernuni-hagen.de/english/research/clusters/catalpa/), [Cognii](https://www.cognii.com), [Duolingo](https://duolingo.com/), [Duolingo English Test](https://englishtest.duolingo.com/), [Educational Testing Service](https://www.ets.org/), [Grammarly](https://grammarly.com/), [iLexIR](https://ilexir.co.uk/), [NBME](https://nbme.org/), and [Newsela](https://newsela.com/). This year, we want to continue helping students to attend the workshop, including the accommodation of the student post-workshop dinner and offering  grants covering best paper presentations. We are hoping to identify sponsors who might be willing to contribute $100 (Bronze), $250 (Silver) or $500 (Gold sponsorship) to subsidize some of the workshop costs. Perks of sponsorship include logos on the workshop website and in the proceedings. If you would like to sponsor the BEA, please send us an [email](mailto:bea.nlp.workshop@gmail.com).

## Call for Papers

The workshop will accept submissions of both full papers and short papers, eligible for either oral or poster presentation.
We solicit papers that incorporate NLP methods, including, but not limited to:
- automated scoring of open-ended textual and spoken responses;
- game-based instruction and assessment;
- educational data mining;
- intelligent tutoring;
- collaborative learning environments;
- peer review;
- grammatical error detection and correction;
- learner cognition;
- spoken dialog;
- multimodal applications;
- annotation standards and schemas;
- tools and applications for classroom teachers, learners, or test developers; and
- use of corpora in educational tools.

### Important Dates

All deadlines are 11:59pm UTC-12 (anywhere on earth).
{: .notice--danger}

| Event                         | Date                |
|-------------------------------|---------------------|
| Submission Deadline           | <strike>March 10</strike> **March 16**, 2024      |
| Notification of Acceptance    | <strike>April 14</strike> April 15, 2024      |
| Camera-ready Papers Due       | April 24, 2024      |
| Pre-recorded Videos Due       | May 19, 2024         |
| Workshop                      | June 20, 2024 |

### Submission Guidelines

To streamline the submission process, we rely on the **ACL submission guidelines** and the **START conference system**, accessible at [https://softconf.com/naacl2024/BEA2024](https://softconf.com/naacl2024/BEA2024/).
All submissions undergo review by the [program committee](#program-committee).

Long, Short, and Demo Papers
: Authors can choose to submit long papers (up to eight (8) pages) or short papers (up to four (4) pages), alongside unlimited references.
After peer review, all accepted papers will be allotted an additional page of content (up to nine for long papers, five for short papers), allowing authors to address reviewer comments.
Authors are strongly urged to present a live demonstration for papers that elaborate on systems.
If opting for this, authors should choose either "long paper + demo" or "short paper + demo" under the "Submission Category" on the submission page.

LaTeX and Word Templates
: Authors must ensure their paper submissions adhere to the general paper formatting guidelines for "*ACL" conferences, found [here](https://acl-org.github.io/ACLPUB/formatting.html), and use the **official ACL style templates**, downloadable [here](https://github.com/acl-org/acl-style-files).
Do not modify these style files or use templates intended for other conferences.
Submissions failing to meet required styles, including paper size, margin width, and font size restrictions, will be rejected without review.

Limitations
: Authors are required to discuss the limitations of their work in a dedicated section titled "Limitations".
This section should be included at the end of the paper, before the references, and it will not count toward the page limit.
This includes both, long and short papers.
Note, prior to the December 2023 cycle, this was optional.

Ethics Policy
: Authors are required to honour the ethical code set out in the [ACL Code of Ethics](https://www.aclweb.org/portal/content/acl-code-ethics).
The consideration of the ethical impact of our research, use of data, and potential applications of our work has always been an important consideration, and as artificial intelligence is becoming more mainstream, these issues are increasingly pertinent.
We ask that all authors read the code, and ensure that their work is conformant to this code.
Authors are encouraged to devote a section of their paper to concerns about the ethical impact of the work and to a discussion of broader impacts of the work, which will be taken into account in the review process.
This discussion may extend into a 5th page (short papers) or 9th page (long papers).

Anonymity
: Given the blind review process, it is essential to ensure that papers remain anonymous.
Authors should avoid self-references that disclose their identity (e.g., ‚ÄúWe previously showed (Smith, 1991)‚Äù), opting instead for citations like ‚ÄúSmith previously showed (Smith, 1991)‚Äù.

Conflicts of Interest
: Authors are required to mark potential reviewers who have co-authored the paper, belong to the same research group or institution, or have had prior exposure to the paper, ensuring transparency in the review process.

Double Submissions
: We adhere to the official ACL double-submission policy.
If papers are submitted to both BEA and another conference or workshop, authors must specify the other event on the title page (as a footnote on the abstract).
Additionally, the title page should state that if the paper is accepted for presentation at BEA, it will be withdrawn from other conferences and workshops.

Republications
: Previously published papers will not be accepted.

### Presentation Guidelines

All accepted papers must be presented at the workshop to appear in the proceedings.
The workshop will include both in-person and virtual presentation options.
**At least one author of each accepted paper must register for the conference by the early registration deadline.**

Long and short papers will be presented orally or as posters as determined by the workshop organizers.
While short papers will be distinguished from long papers in the proceedings, there will be no distinction in the proceedings between papers presented orally and papers presented as posters.

In-person posters
: Poster stands at the venue will be provided for A0 posters, portrait orientation. This means that your actual poster may be smaller than that but you should make sure it fits on the stand provided. Apart from this, we do not have any specific requirements regarding font types, sizes, etc. (just keep in mind that since you are presenting in person, the poster has to be well readable from a distance, so the font should not be too small).

Online posters
: We do not have any specific requirements regarding font types, sizes, etc. In line with the physical posters, it might be a good idea to have your digital poster in portrait orientation. During the workshop, you will be presenting your poster in a "virtual" room mimicking the in-person poster sessions (further details to be provided by ACL / Underline). If you have any further technical questions about virtual presentations, please contact Underline directly at acl2023@underline.io.

In-person and online demos
: In addition to the poster, please demonstrate how your proposed system works on your laptop. Wi-fi connection will be available at the venue for browser-based systems. If you have any further technical questions about virtual presentations, please contact Underline directly at acl2023@underline.io.

Please note that there are no dedicated templates for BEA posters, but for inspiration, you can take a look at the recorded poster talks from previous years' editions of BEA, e.g., [here](https://underline.io/events/325/sessions?eventSessionId=11197&searchGroup=event_session).

###  Share Code & Data on GitHub

If you are interested in sharing your code and data with the BEA community, we created the [#bea-workshop](https://github.com/topics/bea-workshop) topic on GitHub.

## Shared Tasks

In addition to the main workshop track, the workshop has two shared tasks tracks. For more information on how to participate and latest updates, please refer to the shared task websites.

### Task 1: [Automated Prediction of Item Difficulty and Item Response Time (APIDIRT)](/sharedtask/2024)

### Task 2: [Multilingual Lexical Simplification Pipeline (MLSP)](/sharedtask/2024-MLSP)

## Workshop Program

| | June 20, 2024 (General Time in GMT-6) <br> **Location:** Don Alberto 4 (in person) or Underline.io (remote) |
|:--------------- | ----------------------------- |
| **09:00‚Äì09:05** | **Opening remarks** |
| **09:05‚Äì09:50** | [**Keynote by Alla Rozovskaya**](#alla-rozovskaya-cuny) <br> *Multilingual Low-Resource Natural Language Processing for Language Learning* |
| **09:50‚Äì10:30** | **Shared Tasks Session** |
| 09:50‚Äì10:10     | *The BEA 2024 Shared Task on the Multilingual Lexical Simplification Pipeline* (Matthew Shardlow, Fernando Alva-Manchego, Riza Batista-Navarro, Stefan Bott, Saul Calderon Ramirez, R√©mi Cardon, Thomas Fran√ßois, Akio Hayakawa, Andrea Horbach, Anna Huelsing, Yusuke Ide, Joseph Marvin Imperial, Adam Nohejl, Kai North, Laura Occhipinti, Nelson Per√©z Rojas, Nishat Raihan, Tharindu Ranasinghe, Martin Solis Salazar, Sanja Stajner, Marcos Zampieri, and Horacio Saggion) ‚Äì In person |
| 10:10‚Äì10:30 | *Findings from the First Shared Task on Automated Prediction of Difficulty and Response Time for Multiple-Choice Questions* (Victoria Yaneva, Kai North, Peter Baldwin, Le An Ha, Saed Rezayi, Yiyun Zhou, Sagnik Ray Choudhury, Polina Harik, and Brian Clauserr) ‚Äì In person |
| **10:30‚Äì11:00** | **Morning Coffee Break** |
| **11:00‚Äì11:30** | Spotlight talks for Poster / Demo Session A (In-person + Virtual) <br> **Location:** TBD (in person) or Underline.io (remote) |
| **11:30‚Äì12:30** | **Poster / Demo Session A** <br> **Location:** Poster Area / GatherTown |
| **12:30‚Äì14:00** | **Lunch** |
| **14:00‚Äì14:30** | Spotlight talks for Poster / Demo Session B (In-person + Virtual) <br> **Location:** TBD (in person) or Underline.io (remote) |
| **14:30‚Äì15:30** | **Poster / Demo Session B** <br> **Location:** Poster Area / GatherTown |
| **15:30‚Äì16:00** | **Afternoon Coffee Break** |
| **16:00‚Äì17:00** | **Oral Presentations** |
| **17:25‚Äì17:30** | **Closing remarks & Best paper awards** |

### Invited Talks

#### ![Keynote](https://img.shields.io/badge/%20-KEYNOTE-orange?style=flat-square)<a name="#alla-rozovskaya" style="visibility: hidden;">Alla Rozovskaya (CUNY)</a> 

**Alla Rozovskaya**, Queens College, City University of New York<br>
<i>Multilingual Low-Resource Natural Language Processing for Language Learning</i>

**Abstract:** Recent studies on a wide range of NLP tasks have demonstrated the effectiveness of training paradigms that integrate large language models. However, such methods require large amounts of labeled and unlabeled data, limiting their success to a small set of well-resourced languages.
This talk will discuss low-resource approaches for two language learning applications. We will begin with work on generating vocabulary exercises. We will describe an approach that does not require labeled training data and can be used to adapt the exercises to the linguistic profile of the learner. Next, we will discuss our recent work on multilingual grammatical error correction (GEC), addressing the issue of training GEC models for languages with little labeled training data, and the issue of evaluating system performance when high-quality benchmarks are lacking.
{: .notice--primary}
  
**Bio:** Alla Rozovskaya is an Assistant Professor in the Department of Computer Science at Queens College, City University of New York (CUNY), and a member of the Doctoral Faculty of the Computer Science and Linguistics programs at the CUNY Graduate Center. She earned her Ph.D. in Computational Linguistics at the University of Illinois at Urbana-Champaign, under the supervision of Prof. Dan Roth. Her research interests lie broadly in the area of low-resource and multilingual NLP and educational applications. 
{: .notice}

### Accepted Papers

We've received a total of 92 submissions to the main workshop track. After careful review, we've approved the following 38 papers, leading to a 41% acceptance rate for the main workshop.

- *How Good are Modern LLMs in Generating Relevant and High-Quality Questions at Different Bloom's Skill Levels for Indian High School Social Science Curriculum?* (Nicy Scaria, Suma Dharani Chenna and Deepak Subramani)				
- *Synthetic Data Generation for Low-resource Grammatical Error Correction with Tagged Corruption Models* (Felix Stahlberg and Shankar Kumar)				
- *Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models* (Kostiantyn Omelianchuk, Andrii Liubonko, Oleksandr Skurzhanskyi, Artem Chernodub, Oleksandr Korniienko and Igor Samokhin)				
- *Using Adaptive Empathetic Responses for Teaching English* (Li Siyan, Teresa Shao, Julia Hirschberg and Zhou Yu)				
- *Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts* (Donya Rooein, Paul R√∂ttger, Anastassia Shaitarova and Dirk Hovy)				
- *Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction* (Masamune Kobayashi, Masato Mita and Mamoru Komachi)				
- *Can Language Models Guess Your Identity? Analyzing Demographic Biases in AI Essay Scoring* (Alexander Kwako and Christopher Ormerod)				
- *Automated Scoring of Clinical Patient Notes: Findings From the Kaggle Competition and Their Translation into Practice* (Victoria Yaneva, King Yiu Suen, Le An Ha, Janet Mee, Milton Quranda and Polina Harik)				
- *A World CLASSE Student Summary Corpus* (Scott Crossley, Perpetual Baffour, Mihai Dascalu and Stefan Ruseti)				
- *Improving Socratic Question Generation using Data Augmentation and Preference Optimization* (Nischal Ashok Kumar and Andrew Lan)				
- *Scoring with Confidence? ‚Äì Exploring High-confidence Scoring for Saving Manual Grading Effort* (Marie Bexte, Andrea Horbach, Lena Sch√ºtzler, Oliver Christ and Torsten Zesch)				
- *Predicting Initial Essay Quality Scores to Increase the Efficiency of Comparative Judgment Assessments* (Michiel De Vrindt, Ana√Øs Tack, Renske Bouwer, Wim Van Den Noortgate and Marije Lesterhuis)				
- *Improving Transfer Learning for Early Forecasting of Academic Performance by Contextualizing Language Models* (Ahatsham Hayat, Bilal Khan and Mohammad R. Hasan)				
- *Can GPT-4 do L2 analytic assessment?* (Stefano Banno, Hari Krishna Vydana, Kate M. Knill and Mark Gales)				
- *Using Program Repair as a Proxy for Language Models' Feedback Ability in Programming Education* (Charles Arole Koutcheme, Nicola Dainese and Arto Hellas)				
- *Automated Evaluation of Teacher Encouragement of Student-to-Student Interactions in a Simulated Classroom Discussion* (Michael John Ilagan, Beata Beigman Klebanov and Jamie N. Mikeska)				
- *Explainable AI in Language Learning: Linking Empirical Evidence and Theoretical Concepts in Proficiency and Readability Modeling of Portuguese* (Luisa Ribeiro-Flucht, Xiaobin Chen and Detmar Meurers)				
- *Fairness in Automated Essay Scoring: A Comparative Analysis of Algorithms on German Learner Essays from Secondary Education* (Nils-Jonathan Schaller, Yuning Ding, Andrea Horbach, Jennifer Meyer and Thorben Jansen)				
- *Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank* (Alexander Scarlatos, Wanyong Feng, Andrew Lan, Simon Woodhead and Digory Smith)				
- *Avoiding Taylor Swift: Identifying Fairness Issues in Automatically Generated Testing Content* (Kevin Stowe)				
- *Towards Automated Document Revision: Grammatical Error Correction, Fluency Edits, and Beyond* (Masato Mita, Keisuke Sakaguchi, Masato Hagiwara, Tomoya Mizumoto, Jun Suzuki and Kentaro Inui)				
- *Evaluating Vocabulary Usage in LLMs* (Matthew Peter Nicholas Durward and Christopher Thomson)				
- *Exploring LLM Prompting Strategies for Joint Essay Scoring and Feedback Generation* (Maja Stahl, Leon Biermann, Andreas Nehring and Henning Wachsmuth)				
- *Towards Fine-Grained Pedagogical Control over English Grammar Complexity in Educational Text Generation* (Dominik Glandorf and Detmar Meurers)				
- *LLMs in Short Answer Scoring: Limitations and Promise of Zero-Shot and Few-Shot Approaches* (Imran Chamieh, Torsten Zesch and Klaus Giebermann)				
- *Automated Essay Scoring Using Grammatical Variety and Errors with Multi-Task Learning and Item Response Theory* (Kosuke Doi, Katsuhito Sudoh and Satoshi Nakamura)				
- *Error Tracing in Programming: A Path to Personalised Feedback* (Martha Shaka, Diego Carraro and Kenneth N. Brown)				
- *Improving Readability Assessment with Ordinal Log-Loss* (Ho Hung Lim and John S. Y. Lee)				
- *Automated Sentence Generation for a Spaced Repetition Software* (Benjamin Paddags, Daniel Hershcovich and Valkyrie Savage)				
- *Using Large Language Models to Assess Young Students' Writing Revisions* (Tianwen Li, Zhexiong Liu, Lindsay Clare Matsumura, Elaine Lin Wang, Diane Litman and Richard Correnti)				
- *Automatic Crossword Clues Extraction for Language Learning* (Santiago Berruti, Arturo Collazo, Diego Sellanes, Aiala Ros√° and Luis Chiruzzo)				
- *Anna Karenina Strikes Again: Pre-Trained LLM Embeddings May Favor High-Performing Learners* (Abigail Victoria Gurin Schleifer, Beata Beigman Klebanov, Moriah Ariely and Giora Alexandron)				
- *Assessing Student Explanations with Large Language Models Using Fine-Tuning and Few-Shot Learning* (Dan Carpenter,Wookhee Min, Seung Lee, Gamze Ozogul, Xiaoying Zheng and James Lester)				
- *Harnessing GPT to Study Second Language Learner Essays: Can We Use Perplexity to Determine Linguistic Competence?* (Ricardo Mu√±oz S√°nchez, Simon Dobnik and Elena Volodina)				
- *BERT-IRT: Accelerating Item Piloting with BERT Embeddings and Explainable IRT Models* (Kevin P. Yancey, Andrew Runge, Geoffrey T. LaFlair and Phoebe Mulcaire)				
- *Transfer Learning of Argument Mining in Student Essays* (Yuning Ding, Julian Lohmann, Nils-Jonathan Schaller, Thorben Jansen and Andrea Horbach)				
- *Building Robust Content Scoring Models for Student Explanations of Social Justice Science Issues* (Allison Bradford, Kenneth Steimel, BRIAN Riordan and Marcia C. Linn)				
- *From Miscue to Evidence of Difficulty: Analysis of Automatically Detected Miscues in Oral Reading for Feedback Potential* (Beata Beigman Klebanov, Michael Suhan, Tenaha O'Reilly and Zuowei Wang)				

### Shared Task Papers

In addition to the papers accepted to the main workshop track, the workshop will feature 20 shared task papers, including two shared task overview papers and 18 system description papers.

Task 1: Automated Prediction of Item Difficulty and Item Response Time (APIDIRT)
: - *Findings from the First Shared Task on Automated Prediction of Difficulty and Response Time for Multiple-Choice Questions* (Victoria Yaneva, Kai North, Peter Baldwin, Le An Ha, Saed Rezayi, Yiyun Zhou, Sagnik Ray Choudhury, Polina Harik and Brian Clauser)
- *Predicting Item Difficulty and Item Response Time with Scalar-mixed Transformer Encoder Models and Rational Network Regression Heads* (Sebastian Gombert, Lukas Menzel, Daniele Di Mitri and Hendrik Drachsler)
- *UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions* (Ana-Cristina Rogoz and Radu Tudor Ionescu)
- *The British Council submission to the BEA 2024 shared task* (Mariano Felice and Zeynep Duran Karaoz)
- *ITEC at BEA 2024 Shared Task: Predicting Difficulty and Response Time of Medical Exam Questions with Statistical, Machine Learning, and Language Models* (Ana√Øs Tack, Siem Buseyne, Changsheng Chen, Robbe D'hondt, Michiel De Vrindt, Alireza Gharahighehi, Sameh Metwaly, Felipe Kenji Nakano and Ann-Sophie Noreillie)
- *Item Difficulty and Response Time Prediction with Large Language Models: An Empirical Analysis of USMLE Items* (Okan Bulut, Guher Gorgun and Bin Tan)
- *Utilizing Machine Learning to Predict Question Difficulty and Response Time for Enhanced Test Construction* (Rishikesh P. Fulari and Jonathan Rusert)
- *Leveraging Physical and Semantic Features of text item for Difficulty and Response Time Prediction of USMLE Questions* (Gummuluri Venkata Ravi Ram, Ashinee Kesanam and Anand Kumar M)
- *UPN-ICC at BEA 2024 Shared Task: Leveraging LLMs for Multiple-Choice Questions Difficulty Prediction* (George Enrique Duenas, Sergio Jimenez and Geral Eduardo Mateus Ferro)
- *Using Machine Learning to Predict Item Difficulty and Response Time in Medical Tests* (Mehrdad Yousefpoori-Naeim, Shayan Zargari and Zahra Hatami)
- *Large Language Model-based Pipeline for Item Difficulty and Response Time Estimation for Educational Assessments* (Hariram Veeramani, Surendrabikram Thapa, Natarajan Balaji Shankar and Abeer Alwan)
- *UNED team at BEA 2024 Shared Task: Testing different Input Formats for predicting Item Difficulty and Response Time in Medical Exams* (Alvaro Rodrigo, Sergio Moreno-√Ålvarez and Anselmo Pe√±as)

Task 2: Multilingual Lexical Simplification Pipeline (MLSP)
: - *The BEA 2024 Shared Task on the Multilingual Lexical Simplification Pipeline* (Matthew Shardlow, Fernando Alva-Manchego, Riza Batista-Navarro, Stefan Bott, Saul Calderon Ramirez, R√©mi Cardon, Thomas Fran√ßois, Akio Hayakawa, Andrea Horbach, Anna Huelsing, Yusuke Ide, Joseph Marvin Imperial, Adam Nohejl, Kai North, Laura Occhipinti, Nelson Per√©z Rojas, Nishat Raihan, Tharindu Ranasinghe, Martin Solis Salazar, Sanja Stajner, Marcos Zampieri and Horacio Saggion)											
- *TMU-HIT at MLSP 2024: How Well Can GPT-4 Tackle Multilingual Lexical Simplification?* (Taisei Enomoto, Hwichan Kim, Tosho Hirasawa, Yoshinari Nagai, Ayako Sato, Kyotaro Nakajima and Mamoru Komachi)
- *ANU at MLSP-2024: Prompt-based Lexical Simplification for English and Sinhala* (Sandaru Seneviratne and Hanna Suominen)
- *ISEP_Presidency_University at MLSP 2024 Shared Task: Using GPT-3.5 to Generate Substitutes for Lexical Simplification* (Benjamin Dutilleul, Mathis Debaillon and Sandeep Mathias)
- *Machine Translation for Lexical Complexity Prediction and Lexical Simplification* (Petru Theodor Cristea and Sergiu Nisioi)
- *RETUYT-INCO at MLSP 2024: Experiments on Language Simplification using Embeddings, Classifiers and Large Language Models* (Ignacio Sastre, Leandro Alfonso, Facundo Fleitas, Federico Gil, Andr√©s Lucas, Tom√°s Spoturno, Santiago G√≥ngora, Aiala Ros√° and Luis Chiruzzo)
- *GMU at MLSP 2024: Multilingual Lexical Simplification with Transformer Models* (Dhiman Goswami, Kai North and Marcos Zampieri)
- *ITEC at MLSP 2024: Transferring Predictions of Lexical Difficulty from Non-Native Readers* (Ana√Øs Tack)

## Participation

### Registration

If you wish to attend the workshop, you must register with the NAACL conference [here](https://2024.naacl.org/registration/registration/). Select BEA from the list of offered workshops. There is no need to have a paper accepted. The workshop is open to anyone who wishes to attend. **Importantly, at least one author of each accepted paper must register.**

###  Visa information

All visa requests are processed by the ACL's dedicated visa assistance team. To apply for an invitation letter, please follow the information from [https://2024.naacl.org/info-for-participants/#visas](https://2024.naacl.org/info-for-participants/#visas). Specifically, you are required to fill in the [following form](https://docs.google.com/forms/d/e/1FAIpQLSeCow9R7wqdbezUnPc2uu6akLZ26IXNrGp4TY5fEjRFrsmFew/viewform). NAACL's dedicated visa assistance team will then be in touch to help out with your visa letter request.

For other travel information and advice, please check [NAACL's page](https://2024.naacl.org/info-for-participants/).

### Anti-Harassment Policy

SIGEDU adheres to the <a href="https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy">ACL Anti-Harassment Policy</a> for the BEA workshops. Any participant of the workshop who experiences harassment or hostile behavior may contact any current member of the <a href="https://www.aclweb.org/portal/about">ACL Executive Committee</a> or contact <a href="mailto:acl@aclweb.org">Priscilla Rasmussen</a>, who is usually available at the registration desk of the conference. Please be assured that if you approach us, your concerns will be kept in strict confidence, and we will consult with you on any actions taken.

## Workshop Committees

### Organizing Committee

- **General Chair**: [Ekaterina Kochmar](https://ekochmar.github.io/about/), MBZUAI
- **Program Chairs**:
  - [Andrea Horbach](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/andrea.horbach.shtml), Hildesheim University
  - [Ronja Laarmann-Quante](https://www.ltl.uni-due.de/team/ronja-laarmann-quante), Ruhr University Bochum
  - [Marie Bexte](https://www.fernuni-hagen.de/english/research/clusters/catalpa/about-catalpa/members/marie.bexte.shtml), FernUniversit√§t in Hagen
- **Publication Chair**: [Ana√Øs Tack](https://anaistack.github.io/), KU Leuven, imec
- **Shared Tasks Chairs**:
  - [Victoria Yaneva](http://www.victoriayaneva.info/), National Board of Medical Examiners
  - [Jill Burstein](https://sites.google.com/site/jbursteinets/), Duolingo
- **Sponsorship Chair**: [Zheng Yuan](https://www.cl.cam.ac.uk/~zy249/), King's College London

### Program Committee

Tazin Afrin (Educational Testing Service); Erfan Al-Hossami (UNC Charlotte); Desislava Aleksandrova (CBC/Radio-Canada); Giora Alexandron (Weizmann Institute of Science); David Alfter (University of Gothenburg); Jatin Ambasana (Unitedworld School of Computational Intelligence); Alejandro Andrade (Pearson); Nischal Ashok Kumar (University of Massachusetts Amherst); Berk Atil (Penn State University); Shiva Baghel (Data Scientist); Rabin Banjade (University of Memphis); Michael Gringo Angelo Bayona (Trinity College Dublin); Lee Becker (Pearson); Lisa Beinborn (VU Amsterdam); Luca Benedetto (University of Cambridge); Jeanette Bewersdorff (FernUniversit√§t in Hagen); Abhidip Bhattacharyya (CICS UMass); Serge Bibauw (UCLouvain); Ted Briscoe (MBZUAI); Jie Cao (University of Colorado Boulder); Dumitru-Clementin Cercel (University POLITEHNICA of Bucharest); Jeevan Chapagain (University of Memphis); Mei-Hua Chen (Department of Foreign Languages and Literature, Tunghai University); Mark Core (University of Southern California); Steven Coyne (Tohoku University); Sam Davidson (UC Davis); Orphee De Clercq (LT3, Ghent University); Kordula De Kuthy (University of T√ºbingen); Jasper Degraeuwe (Ghent University); Yo Ehara (Tokyo Gakugei University); Yang Deng (Singapore); Chris Develder (Ghent University - imec, Belgium); Yuning Ding (FernUniversit√§t in Hagen); Rahul Divekar (Bentley University); George Due√±as (Universidad Pedagogica Nacional); Mariano Felice (British Council); Nigel Fernandez (University of Massachusetts Amherst); Michael Flor (Educational Testing Service); Jennifer Frey (Institute for Applied Linguistics, Eurac Research); Kotaro Funakoshi (Tokyo Institute of Technology); Thomas Gaillat (Universit√© Rennes 2); Diana Galvan-Sosa (Tohoku University); Ashwinkumar Ganesan (UMBC, Amazon); Rujun Gao (Texas A&M University); Ritik Garg (IIITD); Christian Gold (FernUniversit√§t in Hagen); Sebastian Gombert (DIPF, Leibniz Institute for Research and Information in Education); Cyril Goutte (National Research Council Canada); Abigail Gurin Schleifer (The Weizmann Institute of Science); Handoko Handoko (Universitas Andalas); Ching Nam Hang (Department of Computer Science, City University of Hong Kong); Jiangang Hao (Educational Testing Service); Nicolas Hernandez (Nantes University - LS2N); Heiko Holz (Ludwigsburg University of Education); Chieh-Yang Huang (Penn State University); Chung-Chi Huang (Frostburg State University); Anna Huelsing (Universit√§t Hildesheim); Joseph Marvin Imperial (University of Bath, National University); Radu Tudor Ionescu (University of Bucharest); Qinjin Jia (North Carolina State University); Helen Jin (University of Pennsylvania); Ioana Jivet (Goethe University Frankfurt); L√©ane Jourdan (University of Nantes); Anisia Katinskaia (University of Helsinki); Elma Kerz (RWTH Aachen Univeristy); Fazel Keshtkar (St. John's University, NY); Mamoru Komachi (Hitotsubashi University); Roland Kuhn (National Research Council of Canada (NRC)); Alexander Kwako (University of California, Los Angeles); Kristopher Kyle (University of Oregon); Antonio Laverghetta Jr. (University of South Florida); Seolhwa Lee (Technical University of Darmstadt); Arun Balajiee Lekshmi Narayanan (University of Pittsburgh); Yudong Liu (Western Washington University); Zhexiong Liu (University of Pittsburgh); Julian Lohmann (Christian-Albrechts-Universit√§t zu Kiel); Anastassia Loukina (Grammarly Inc.); Jiaying Lu (Emory University); Crisron Rudolf Lucas (UCD); Jakub Macina (ETH Zurich); Nitin Madnani (ETS); Arianna Masciolini (Spr√•kbanken Text, Department of Swedish, Multilingualism, Language Technology, University of Gothenburg); Sandeep Mathias (Presidency University, Bangalore); Hunter McNichols (University of Massachusetts Amherst); Amit Kumar Mishra (Amity University Madhya Pradesh); Masato Mita (CyberAgent); Phoebe Mulcaire (Duolingo); Laura Musto (Facultad de Informaci√≥n y Comunicaci√≥n, Universidad de la Rep√∫blica); Farah Nadeem (The World Bank); Sungjin Nam (ACT, Inc); Diane Napolitano (Associated Press); Arun Balajiee Lekshmi Narayanan (University of Pittsburgh); Tanya Nazaretsky (EPFL); Kamel Nebhi (Education First); Hwee Tou Ng (National University of Singapore); Huy Nguyen (Amazon); Gebregziabihier Nigusie (Mizan-Tepi University); Christina Niklaus (University of St.Gallen); S Jaya Nirmala (NIT Trichy India); Eda Okur (Intel Labs); Kostiantyn Omelianchuk (Grammarly); Amin Omidvar (York University); Ulrike Pado (Hochschule f√ºr Technik Stuttgart); Chanjun Park (Upstage); Udita Patel (Amazon); Long Qin (Alibaba Cloud); Mengyang Qiu (University at Buffalo); Mart√≠ Quixal (University of T√ºbingen); Manav Rathod (Glean); Hanumant Redkar (Goa University); Robert Reynolds (Brigham Young University); Frankie Robertson (University of Jyv√§skyl√§); Aiala Ros√° (Universidad de la Rep√∫blica); Alla Rozovskaya (City University of New York); Josef Ruppenhofer (Fernuniversit√§t in Hagen); Omer Salem; Nicy Scaria (Indian Institute of Science); Nils-Jonathan Schaller (Christian-Albrechts-Universit√§t zu Kiel); Gyu-Ho Shin (University of Illinois Chicago); Mayank Soni (ADAPT Center, Trinity College Dublin); Katherine Stasaski (Salesforce AI Research); Helmer Strik (Radboud University Nijmegen); Hakyung Sung (University of Oregon); Abhijit Suresh (Reddit Inc.); Chee Wei Tan (Nanyang Technological University); Zhongwei Teng (Duolingo); Xiaoyi Tian (University of Florida); Sowmya Vajjala (National Research Council, Canada); Giulia Venturi (Institute for Computational Linguistics "A. Zampolli"); Anthony Verardi (Duolingo English Test); Elena Volodina (University of Gothenburg, Sweden); Taro Watanabe (Nara Institute of Science and Technology); Michael White (The Ohio State University); Alistair Willis (The Open University, UK); Man Fai Wong (City University of Hong Kong); Simon Woodhead (Eedi); Changrong Xiao (Tsinghua University); Roman Yangarber (University of Helsinki); Su-Youn Yoon (EduLab); Marcos Zampieri (George Mason University); Fabian Zehner (DIPF, Leibniz Institute for Research and Information in Education); Torsten Zesch (FernUniversit√§t in Hagen); Jing Zhang (Emory University); Yiyun Zhou (NBME); Jessica Zipf (University of Konstanz); Michael Zock (CNRS, (LIF) University of Aix-Marseille); Bowei Zou (Institute for Infocomm Research (I2R), A*STAR, Singapore).
